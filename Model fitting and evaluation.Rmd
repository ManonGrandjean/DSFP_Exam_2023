---
title: "Model fitting and evaluation"
author: "Manon Grandjean"
date: "2023-05-31"
output: html_document
---

```{r load libraries}
library(tidyverse)
library(tsibble)
library(fabletools)
library(fable)
library(feasts)
library(gridExtra)

options(scipen=999)
```


```{r Load and prep data}
df <- read.csv("Azure2015Data.csv")

# fix date format
df$datetime <- as.POSIXct(df$datetime, format="%Y-%m-%d %H:%M:%S", tz="UTC")

# remove duplicate rows, create logical var for failure, remove unnecessary cols, arrange temporally for easy splitting
df <- df %>%
  distinct(datetime, machineID, .keep_all = TRUE) %>%
  mutate(failureYN = case_when(failure == '' ~ 0, failure != '' ~ 1)) %>% # also errorYN?
  subset(select = -c(X, Unnamed..0)) %>%
  arrange(datetime, machineID)
```


```{r create error, failure, and component variables}
# vars in df:
# logical: (error1+2+3+4+5, failure_comp1+2+3+4, replace_comp1+2+3+4) = 13 vars
# time since: ---||--- = 13 vars


# https://stackoverflow.com/questions/71284863/time-since-last-event-of-grouped-data-in-r
df <- df %>%
  group_by(machineID) %>%
  # days since any error and any failure
  mutate(last_error = if_else(errorID != "", datetime, NA)) %>%
  mutate(last_failure = if_else(failure != "", datetime, NA)) %>%
  fill(last_error) %>%
  fill(last_failure) %>%
  mutate(daysSinceError = as.numeric(floor(difftime(datetime, last_error, tz="UTC", units="days")))) %>%
  mutate(daysSinceFailure = as.numeric(floor(difftime(datetime, last_failure, tz="UTC", units="days")))) %>%
  # logical vars for each type error/failure/comp (not necessary)
  # daysSince vars for each type of error/failure/comp
  mutate(
    lastError1 = if_else(errorID == "error1", datetime, NA),
    lastError2 = if_else(errorID == "error2", datetime, NA),
    lastError3 = if_else(errorID == "error3", datetime, NA),
    lastError4 = if_else(errorID == "error4", datetime, NA),
    lastError5 = if_else(errorID == "error5", datetime, NA),
    lastFailureComp1 = if_else(failure == "comp1", datetime, NA),
    lastFailureComp2 = if_else(failure == "comp2", datetime, NA),
    lastFailureComp3 = if_else(failure == "comp3", datetime, NA),
    lastFailureComp4 = if_else(failure == "comp4", datetime, NA),
    lastComp1Replacement = if_else(comp == "comp1", datetime, NA),
    lastComp2Replacement = if_else(comp == "comp2", datetime, NA),
    lastComp3Replacement = if_else(comp == "comp3", datetime, NA),
    lastComp4Replacement = if_else(comp == "comp4", datetime, NA)
  ) %>%
  fill(lastError1,lastError2,lastError3,lastError4,lastError5,lastFailureComp1,lastFailureComp2,lastFailureComp3,
       lastFailureComp4,lastComp1Replacement,lastComp2Replacement,lastComp3Replacement,lastComp4Replacement) %>%
  mutate(
    daysSinceError1 = as.numeric(floor(difftime(datetime, lastError1, tz="UTC", units="days"))),
    daysSinceError2 = as.numeric(floor(difftime(datetime, lastError2, tz="UTC", units="days"))),
    daysSinceError3 = as.numeric(floor(difftime(datetime, lastError3, tz="UTC", units="days"))),
    daysSinceError4 = as.numeric(floor(difftime(datetime, lastError4, tz="UTC", units="days"))),
    daysSinceError5 = as.numeric(floor(difftime(datetime, lastError5, tz="UTC", units="days"))),
    daysSinceFailure1 = as.numeric(floor(difftime(datetime, lastFailureComp1, tz="UTC", units="days"))),
    daysSinceFailure2 = as.numeric(floor(difftime(datetime, lastFailureComp2, tz="UTC", units="days"))),
    daysSinceFailure3 = as.numeric(floor(difftime(datetime, lastFailureComp3, tz="UTC", units="days"))),
    daysSinceFailure4 = as.numeric(floor(difftime(datetime, lastFailureComp4, tz="UTC", units="days"))),
    daysSinceReplace1 = as.numeric(floor(difftime(datetime, lastComp1Replacement, tz="UTC", units="days"))),
    daysSinceReplace2 = as.numeric(floor(difftime(datetime, lastComp2Replacement, tz="UTC", units="days"))),
    daysSinceReplace3 = as.numeric(floor(difftime(datetime, lastComp3Replacement, tz="UTC", units="days"))),
    daysSinceReplace4 = as.numeric(floor(difftime(datetime, lastComp4Replacement, tz="UTC", units="days")))
  ) %>%
  # remove unnecessary columns
  subset(select = -c(last_error,last_failure,lastError1,lastError2,lastError3,lastError4,lastError5,
                     lastFailureComp1,lastFailureComp2,lastFailureComp3,lastFailureComp4,
                     lastComp1Replacement,lastComp2Replacement,lastComp3Replacement,lastComp4Replacement))

# do I maybe need to replace NAs in daysSince vars with 0?
```


```{r Aggregate to daily}
# aggregate to daily
df$date <- as.Date(df$datetime, "%m/%d/%Y")
df_daily <- aggregate(cbind(volt,rotate,pressure,vibration)
                      ~ date + machineID,
                      df, FUN = "mean", drop = FALSE)


# get model and age info for each machine ID
df_daily <- merge(df_daily, subset(count(df, machineID, age, model), select = -c(n)), by = "machineID")

# add failure and error info for a day and machine if any
df_daily <- merge(df_daily, 
                  unique(df[df$failureYN==1,][,c("machineID","failureYN","date")]),
                  by = c("machineID", "date"), all.x = TRUE)
df_daily$failureYN <- gtools::na.replace(df_daily$failureYN, 0)

# merge df[,12:27] onto df_daily by date and machineID
df_daily <- merge(df_daily, 
                  distinct(df[,c(1,28,13:27)], machineID, date, .keep_all = TRUE),
                  by = c("machineID", "date"))

# arrange
df_daily <- arrange(df_daily, date, machineID)

# make machineID factor (because it is) so logreg will be accurate
df_daily$machineID <- as.factor(df_daily$machineID)
```


```{r Make lag predictors}
df_daily <- df_daily %>%
  group_by(machineID) %>%
  mutate(lag_1d_volt = lag(volt, n = 1),
         lag_2d_volt = lag(volt, n = 2),
         lag_3d_volt = lag(volt, n = 3),
         lag_4d_volt = lag(volt, n = 4),
         lag_5d_volt = lag(volt, n = 5),
         lag_6d_volt = lag(volt, n = 6),
         lag_7d_volt = lag(volt, n = 7),
         lag_8d_volt = lag(volt, n = 8),
         lag_9d_volt = lag(volt, n = 9),
         lag_10d_volt = lag(volt, n = 10),
         
         lag_1d_rotate = lag(rotate, n = 1),
         lag_2d_rotate = lag(rotate, n = 2),
         lag_3d_rotate = lag(rotate, n = 3),
         lag_4d_rotate = lag(rotate, n = 4),
         lag_5d_rotate = lag(rotate, n = 5),
         lag_6d_rotate = lag(rotate, n = 6),
         lag_7d_rotate = lag(rotate, n = 7),
         lag_8d_rotate = lag(rotate, n = 8),
         lag_9d_rotate = lag(rotate, n = 9),
         lag_10d_rotate = lag(rotate, n = 10),
         
         lag_1d_pressure = lag(pressure, n = 1),
         lag_2d_pressure = lag(pressure, n = 2),
         lag_3d_pressure = lag(pressure, n = 3),
         lag_4d_pressure = lag(pressure, n = 4),
         lag_5d_pressure = lag(pressure, n = 5),
         lag_6d_pressure = lag(pressure, n = 6),
         lag_7d_pressure = lag(pressure, n = 7),
         lag_8d_pressure = lag(pressure, n = 8),
         lag_9d_pressure = lag(pressure, n = 9),
         lag_10d_pressure = lag(pressure, n = 10),
         
         lag_1d_vibration = lag(vibration, n = 1),
         lag_2d_vibration = lag(vibration, n = 2),
         lag_3d_vibration = lag(vibration, n = 3),
         lag_4d_vibration = lag(vibration, n = 4),
         lag_5d_vibration = lag(vibration, n = 5),
         lag_6d_vibration = lag(vibration, n = 6),
         lag_7d_vibration = lag(vibration, n = 7),
         lag_8d_vibration = lag(vibration, n = 8),
         lag_9d_vibration = lag(vibration, n = 9),
         lag_10d_vibration = lag(vibration, n = 10),
  )
```



```{r Train + make forecasts}
# split into train and test
# train on 9 months = 75% of data = up to and including index 27300
train <- df_daily[1:27300,]
test <- df_daily[27301:36500,]
```


# Failure prediction
predictors:
- machineID (as factor)
- date ?
- volt + rotate + pressure + vibration
- age + model
- daysSinceFailure + daysSinceError
- daysSinceError_x + daysSinceFailure_x + daysSinceReplace_x



oooh daysSinceFailure is always going to be 0 when failureYN is 1



Logistic regression models:
*model0* = date + machineID (base for all others?)
*model1* = IoT measures (volt + rotate + pressure + vibration)
*model2* = IoT measures + machine characteristics (age + model)
*model3* = IoT measures + daysSinceFailure                                                daysSinceFailure = Faulty?
*model4* = IoT measures + daysSinceFailure + machine characteristics                      daysSinceFailure = Faulty?
*model5* = IoT measures + daysSinceFailure + daysSinceError                               daysSinceFailure = Faulty?
*model6* = IoT measures + daysSinceFailure + daysSinceError + machine characteristics     daysSinceFailure = Faulty?
*model7* = IoT measures + daysSinceError
*model8* = IoT measures + daysSinceError + machine characteristics

*model9* = IoT measures and lag predictors
*model10* = IoT measures, machine characteristics, and lag predictors
*model11* = IoT measures and lag predictors + daysSinceError
*model12* = IoT measures, machine characteristics, and lag predictors + daysSinceError    (+daysSinceFailure (if LAST failure))

(if date + machineID are base for all the others, they will be model1b model2b etc.)

```{r Fitting logistic regression models}
model0 <- glm(failureYN ~ date + machineID, 
              family=binomial(link='logit'), 
              data = train)

model1 <- glm(failureYN ~ volt + rotate + pressure + vibration, 
              family=binomial(link='logit'), 
              data = train)

model2 <- glm(failureYN ~ volt + rotate + pressure + vibration + age + model, 
              family=binomial(link='logit'), 
              data = train)

# daysSinceFailure (which is probably a bad predictor) (unless it was days since LAST failure)
#model3 <- glm(failureYN ~ volt + rotate + pressure + vibration + daysSinceFailure, 
#              family=binomial(link='logit'), 
#              data = train)
#model4 <- glm(failureYN ~ volt + rotate + pressure + vibration + daysSinceFailure + age + model, 
#              family=binomial(link='logit'), 
#              data = train)
#model5 <- glm(failureYN ~ volt + rotate + pressure + vibration + daysSinceFailure + daysSinceError, 
#              family=binomial(link='logit'), 
#              data = train)
#model6 <- glm(failureYN ~ volt + rotate + pressure + vibration + daysSinceFailure + daysSinceError + age + model, 
#              family=binomial(link='logit'), 
#              data = train)

model7 <- glm(failureYN ~ volt + rotate + pressure + vibration + daysSinceError, 
              family=binomial(link='logit'), 
              data = train)

model8 <- glm(failureYN ~ volt + rotate + pressure + vibration + daysSinceError + age + model, 
              family=binomial(link='logit'), 
              data = train)


# with lag predictors:
model9 <- glm(failureYN ~ volt + rotate + pressure + vibration + 
                lag_1d_volt + lag_2d_volt + lag_3d_volt + lag_4d_volt + lag_5d_volt + lag_6d_volt + lag_7d_volt + lag_8d_volt +
                lag_9d_volt + lag_10d_volt + lag_1d_rotate + lag_2d_rotate + lag_3d_rotate + lag_4d_rotate + lag_5d_rotate +
                lag_6d_rotate + lag_7d_rotate + lag_8d_rotate + lag_9d_rotate + lag_10d_rotate + 
                lag_1d_pressure + lag_2d_pressure + lag_3d_pressure + lag_4d_pressure + lag_5d_pressure +
                lag_6d_pressure + lag_7d_pressure + lag_8d_pressure + lag_9d_pressure + lag_10d_pressure +
                lag_1d_vibration + lag_2d_vibration + lag_3d_vibration + lag_4d_vibration + lag_5d_vibration + 
                lag_6d_vibration + lag_7d_vibration + lag_8d_vibration + lag_9d_vibration + lag_10d_vibration, 
              family=binomial(link='logit'), 
              data = train)

model10 <- glm(failureYN ~ volt + rotate + pressure + vibration + age + model +
                lag_1d_volt + lag_2d_volt + lag_3d_volt + lag_4d_volt + lag_5d_volt + lag_6d_volt + lag_7d_volt + lag_8d_volt +
                lag_9d_volt + lag_10d_volt + lag_1d_rotate + lag_2d_rotate + lag_3d_rotate + lag_4d_rotate + lag_5d_rotate +
                lag_6d_rotate + lag_7d_rotate + lag_8d_rotate + lag_9d_rotate + lag_10d_rotate + 
                lag_1d_pressure + lag_2d_pressure + lag_3d_pressure + lag_4d_pressure + lag_5d_pressure +
                lag_6d_pressure + lag_7d_pressure + lag_8d_pressure + lag_9d_pressure + lag_10d_pressure +
                lag_1d_vibration + lag_2d_vibration + lag_3d_vibration + lag_4d_vibration + lag_5d_vibration + 
                lag_6d_vibration + lag_7d_vibration + lag_8d_vibration + lag_9d_vibration + lag_10d_vibration, 
              family=binomial(link='logit'), 
              data = train)

model11 <- glm(failureYN ~ volt + rotate + pressure + vibration + daysSinceError + 
                lag_1d_volt + lag_2d_volt + lag_3d_volt + lag_4d_volt + lag_5d_volt + lag_6d_volt + lag_7d_volt + lag_8d_volt +
                lag_9d_volt + lag_10d_volt + lag_1d_rotate + lag_2d_rotate + lag_3d_rotate + lag_4d_rotate + lag_5d_rotate +
                lag_6d_rotate + lag_7d_rotate + lag_8d_rotate + lag_9d_rotate + lag_10d_rotate + 
                lag_1d_pressure + lag_2d_pressure + lag_3d_pressure + lag_4d_pressure + lag_5d_pressure +
                lag_6d_pressure + lag_7d_pressure + lag_8d_pressure + lag_9d_pressure + lag_10d_pressure +
                lag_1d_vibration + lag_2d_vibration + lag_3d_vibration + lag_4d_vibration + lag_5d_vibration + 
                lag_6d_vibration + lag_7d_vibration + lag_8d_vibration + lag_9d_vibration + lag_10d_vibration, 
              family=binomial(link='logit'), 
              data = train)

model12 <- glm(failureYN ~ volt + rotate + pressure + vibration + age + model + daysSinceError + 
                lag_1d_volt + lag_2d_volt + lag_3d_volt + lag_4d_volt + lag_5d_volt + lag_6d_volt + lag_7d_volt + lag_8d_volt +
                lag_9d_volt + lag_10d_volt + lag_1d_rotate + lag_2d_rotate + lag_3d_rotate + lag_4d_rotate + lag_5d_rotate +
                lag_6d_rotate + lag_7d_rotate + lag_8d_rotate + lag_9d_rotate + lag_10d_rotate + 
                lag_1d_pressure + lag_2d_pressure + lag_3d_pressure + lag_4d_pressure + lag_5d_pressure +
                lag_6d_pressure + lag_7d_pressure + lag_8d_pressure + lag_9d_pressure + lag_10d_pressure +
                lag_1d_vibration + lag_2d_vibration + lag_3d_vibration + lag_4d_vibration + lag_5d_vibration + 
                lag_6d_vibration + lag_7d_vibration + lag_8d_vibration + lag_9d_vibration + lag_10d_vibration, 
              family=binomial(link='logit'), 
              data = train)

# Warning: glm.fit: algorithm did not converge
# https://www.statology.org/glm-fit-algorithm-did-not-converge/
```


```{r model summaries}
summary(model0)
```



```{r m12 inspecting estimates for each predictor}
s12 <- summary(model12)
estimates12 <- s12$coefficients[2:50,1]
coef12 <- as.data.frame(estimates12)
coef12 <- cbind(Predictor = rownames(coef12), coef12)
coef12$order <- 1:49
coef12 <- mutate(coef12, 
                 category = case_when(Predictor == 'volt' ~ 'IoT measure',
                                      Predictor == 'rotate' ~ 'IoT measure',
                                      Predictor == 'pressure' ~ 'IoT measure',
                                      Predictor == 'vibration' ~ 'IoT measure',
                                      Predictor == 'age' ~ 'Machine characteristic',
                                      Predictor == 'modelmodel2' ~ 'Machine characteristic',
                                      Predictor == 'modelmodel3' ~ 'Machine characteristic',
                                      Predictor == 'modelmodel4' ~ 'Machine characteristic',
                                      Predictor == 'daysSinceError' ~ 'Maintenance info',
                                      grepl('d_volt',Predictor) ~ 'Lag volt',
                                      grepl('d_rotate',Predictor) ~ 'Lag rotate',
                                      grepl('d_pressure',Predictor) ~ 'Lag pressure',
                                      grepl('d_vibration',Predictor) ~ 'Lag vibration'
                                      ))

options(scipen=0)

ggplot(coef12, aes(x = estimates12, y = reorder(Predictor, -order), fill = reorder(category, order)))+
  geom_col()+
  ggtitle("Estimates for model 12")+
  theme_light()+
  xlab("Estimate")+
  ylab("Predictor")+
  scale_fill_discrete(name = "")

options(scipen=999)
```

```{r m9}
s9 <- summary(model9)
estimates9 <- s9$coefficients[2:45,1]
coef9 <- as.data.frame(estimates9)
coef9 <- cbind(Predictor = rownames(coef9), coef9)
coef9$order <- 1:44
coef9 <- mutate(coef9, 
                 category = case_when(Predictor == 'volt' ~ 'IoT measure',
                                      Predictor == 'rotate' ~ 'IoT measure',
                                      Predictor == 'pressure' ~ 'IoT measure',
                                      Predictor == 'vibration' ~ 'IoT measure',
                                      grepl('d_volt',Predictor) ~ 'Lag volt',
                                      grepl('d_rotate',Predictor) ~ 'Lag rotate',
                                      grepl('d_pressure',Predictor) ~ 'Lag pressure',
                                      grepl('d_vibration',Predictor) ~ 'Lag vibration'
                                      ))

options(scipen=0)

ggplot(coef9, aes(x = estimates9, y = reorder(Predictor, -order), fill = reorder(category, order)))+
  geom_col()+
  ggtitle("Estimates for model 9")+
  theme_light()+
  xlab("Estimate")+
  ylab("Predictor")+
  scale_fill_discrete(name = "")

options(scipen=999)
```



```{r LogReg Model predictions on test set}
# Save probability of failure (PoF) from each model into the test set
test$PoF_model1 <- predict(model1, newdata = test, type = 'response')
test$PoF_model2 <- predict(model2, newdata = test, type = 'response')
test$PoF_model3 <- predict(model3, newdata = test, type = 'response')
test$PoF_model4 <- predict(model4, newdata = test, type = 'response')
test$PoF_model5 <- predict(model5, newdata = test, type = 'response')
test$PoF_model6 <- predict(model6, newdata = test, type = 'response')
test$PoF_model7 <- predict(model7, newdata = test, type = 'response')
test$PoF_model8 <- predict(model8, newdata = test, type = 'response')
test$PoF_model9 <- predict(model9, newdata = test, type = 'response')
test$PoF_model10 <- predict(model10, newdata = test, type = 'response')
test$PoF_model11 <- predict(model11, newdata = test, type = 'response')
test$PoF_model12 <- predict(model12, newdata = test, type = 'response')
test$PoF_model0 <- predict(model0, newdata = test, type = 'response')

```


```{r plot PoF vs real failure}
plotPoF <- function(machine){
  gridExtra::grid.arrange(ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_line(aes(y=PoF_model1))+
                            theme_light()+ylab("")+xlab("Model 1"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_line(aes(y=PoF_model9))+
                            theme_light()+ylab("")+xlab("Model 9"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_line(aes(y=PoF_model12))+
                            theme_light()+ylab("")+xlab("Model 12"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity")+
                            theme_light()+ylab("")+xlab("Actual failure"),
                          ncol = 1, left = "Probability of failure (PoF)"
  )
}

plotPoF_allmodels <- function(machine){
  ggplot(test[test$machineID==machine,], aes(x=date))+
  geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5)+
  geom_line(aes(y=PoF_model1), color = "#F8766D")+
  geom_line(aes(y=PoF_model2), color = "#E58700")+
  geom_line(aes(y=PoF_model7), color = "#DBD516")+ # gul
  geom_line(aes(y=PoF_model8), color = "#6BB100")+
  geom_line(aes(y=PoF_model9), color = "#00C0AF")+
  geom_line(aes(y=PoF_model10), color = "#00B0F6")+
  geom_line(aes(y=PoF_model11), color = "#B983FF")+
  geom_line(aes(y=PoF_model12), color = "#FD61D1")+
  geom_line(aes(y=PoF_model0), color = "#FFA18A")+
  theme_light()
}

plotPoF2 <- function(machine){
  gridExtra::grid.arrange(ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model0))+
                            theme_light()+ylab("")+xlab("Model 0"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model1))+
                            theme_light()+ylab("")+xlab("Model 1"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model2))+
                            theme_light()+ylab("")+xlab("Model 2"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model7))+
                            theme_light()+ylab("")+xlab("Model 7"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model8))+
                            theme_light()+ylab("")+xlab("Model 8"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model9))+
                            theme_light()+ylab("")+xlab("Model 9"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model10))+
                            theme_light()+ylab("")+xlab("Model 10"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model11))+
                            theme_light()+ylab("")+xlab("Model 11"),
                          ggplot(test[test$machineID==machine,], aes(x=date))+
                            geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
                            geom_line(aes(y=PoF_model12))+
                            theme_light()+ylab("")+xlab("Model 12"),
                          #ggplot(test[test$machineID==machine,], aes(x=date))+
                          #  geom_bar(aes(y=failureYN), stat = "identity")+
                          #  theme_light()+ylab("")+xlab("Actual failure"),
                          ncol = 3, left = "Probability of failure (PoF)"
  )
}

plot_IoT_PoF <- function(machine, title){
 gridExtra::grid.arrange(
  ggplot(test[test$machineID==machine,], aes(x=date))+geom_line(aes(y=volt))+theme_light()+xlab(""),
  ggplot(test[test$machineID==machine,], aes(x=date))+geom_line(aes(y=rotate))+theme_light()+xlab(""),
  ggplot(test[test$machineID==machine,], aes(x=date))+geom_line(aes(y=pressure))+theme_light()+xlab(""),
  ggplot(test[test$machineID==machine,], aes(x=date))+geom_line(aes(y=vibration))+theme_light()+xlab(""),
  ggplot(test[test$machineID==machine,], aes(x=date))+geom_bar(aes(y=failureYN), stat = "identity", alpha = 0.5, fill = "#009DA6")+
    geom_line(aes(y=PoF_model12))+theme_light()+ylab("Failure"),
  ncol = 1, heights = c(1,1,1,1,1.3), top = title
) 
}


plotPoF(21)
plotPoF_allmodels(21)
plotPoF2(99)
plot_IoT_PoF(21, "PoF machine 21")
```


```{r Confusion matrices}
# Set decision boundary
decision_boundary <- 0.5

# Create 0-1 predictions from models
test <- test %>%
  mutate(
    Failure_m1 = ifelse(PoF_model1 < decision_boundary, 0, 1),
    Failure_m2 = ifelse(PoF_model2 < decision_boundary, 0, 1),
    Failure_m7 = ifelse(PoF_model7 < decision_boundary, 0, 1),
    Failure_m8 = ifelse(PoF_model8 < decision_boundary, 0, 1),
    Failure_m9 = ifelse(PoF_model9 < decision_boundary, 0, 1),
    Failure_m10 = ifelse(PoF_model10 < decision_boundary, 0, 1),
    Failure_m11 = ifelse(PoF_model11 < decision_boundary, 0, 1),
    Failure_m12 = ifelse(PoF_model12 < decision_boundary, 0, 1),
    Failure_m0 = ifelse(PoF_model0 < decision_boundary, 0, 1),
  )

ConfMat1 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m1), positive = "1") #err
ConfMat2 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m2), positive = "1") #err
ConfMat7 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m7), positive = "1")
ConfMat8 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m8), positive = "1")
ConfMat9 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m9), positive = "1")
ConfMat10 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m10), positive = "1")
ConfMat11 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m11), positive = "1")
ConfMat12 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m12), positive = "1")
ConfMat0 <- confusionMatrix(reference = as.factor(test$failureYN), as.factor(test$Failure_m0), positive = "1") #err

ConfMat12
```



# Forecasts

```{r prepare data for forecasting}
# train and test tsibbles
tsrain <- as_tsibble(train, key = machineID, index = date)
tsest <- as_tsibble(test, key = machineID, index = date)

# empty data to fill with forecasts
future_Q4 <- tsest
# machineID, date, age, and model stay the same (we know these ex ante)
# lag values in the first n rows per machine are actually valid, but don't know how to preserve those
future_Q4[,3:6] <- NA
future_Q4[,9:82] <- NA
future_Q4 <- as_tsibble(future_Q4, key = machineID, index = date)

```


```{r functions to return report and forecast plot}
machine_report <- function(fit, id){
  report(fit[fit$machineID == id,])
}

machine_forecast <- function(fc, actual, id){
  fc2 <- fc[fc$machineID == id,]
  actual2 <- actual[actual$machineID == id,]
  
  fc2 |>
    autoplot(actual2)+
    theme_light()
}
```

# Variables to forecast
*needs forecasting:* volt + rotate + pressure + vibration + daysSinceError
*do not need forecasting:* age + model + machineID + date + all lag predictors (can be calculated after IoT forecasts)


```{r Fit forecast models}
# fit all (TSLM + Seasonal Naïve model) to compare
fit_volt <- model(tsrain, LM=TSLM(volt ~ trend() + season()),SN=SNAIVE(volt))
fit_rotate <- model(tsrain, LM=TSLM(rotate ~ trend() + season()),SN=SNAIVE(rotate))
fit_pressure <- model(tsrain, LM=TSLM(pressure ~ trend() + season()),SN=SNAIVE(pressure))
fit_vibration <- model(tsrain, LM=TSLM(vibration ~ trend() + season()),SN=SNAIVE(vibration))
fit_daysSinceError <- model(tsrain, LM=TSLM(daysSinceError ~ trend() + season()),SN=SNAIVE(daysSinceError))

# produce forecasts
fc_volt <- forecast(fit_volt, new_data = future_Q4[,1:2])
fc_rotate <- forecast(fit_rotate, new_data = future_Q4[,1:2])
fc_pressure <- forecast(fit_pressure, new_data = future_Q4[,1:2])
fc_vibration <- forecast(fit_vibration, new_data = future_Q4[,1:2])
fc_daysSinceError <- forecast(fit_daysSinceError, new_data = future_Q4[,1:2])
```


```{r Test forecast accuracy of the different models}
# Point forecast accuracy: How much error?
# The average of each score across machines
accuracy(fit_volt) %>% select(.model, machineID, MAE, MASE, RMSE, MAPE) %>%
  aggregate(cbind(MAE, MASE, RMSE, MAPE) ~ .model, FUN = "mean", drop = FALSE)

accuracy(fit_rotate) %>% select(.model, machineID, MAE, MASE, RMSE, MAPE) %>%
  aggregate(cbind(MAE, MASE, RMSE, MAPE) ~ .model, FUN = "mean", drop = FALSE)

accuracy(fit_pressure) %>% select(.model, machineID, MAE, MASE, RMSE, MAPE) %>%
  aggregate(cbind(MAE, MASE, RMSE, MAPE) ~ .model, FUN = "mean", drop = FALSE)

accuracy(fit_vibration) %>% select(.model, machineID, MAE, MASE, RMSE, MAPE) %>%
  aggregate(cbind(MAE, MASE, RMSE, MAPE) ~ .model, FUN = "mean", drop = FALSE)

accuracy(fit_daysSinceError) %>% select(.model, machineID, MAE, MASE, RMSE, MAPE) %>%
  aggregate(cbind(MAE, MASE, RMSE, MAPE) ~ .model, FUN = "mean", drop = FALSE)


# Distributional forecast accuracy: Continuous ranked probability score (CRPS)
fc_volt %>% accuracy(rbind(tsrain, tsest), measures = list(crps=CRPS, skill=skill_score(CRPS))) %>%
  aggregate(cbind(crps, skill) ~ .model, FUN = "mean", drop = FALSE)

fc_rotate %>% accuracy(rbind(tsrain, tsest), measures = list(crps=CRPS, skill=skill_score(CRPS))) %>%
  aggregate(cbind(crps, skill) ~ .model, FUN = "mean", drop = FALSE)

fc_pressure %>% accuracy(rbind(tsrain, tsest), measures = list(crps=CRPS, skill=skill_score(CRPS))) %>%
  aggregate(cbind(crps, skill) ~ .model, FUN = "mean", drop = FALSE)

fc_vibration %>% accuracy(rbind(tsrain, tsest), measures = list(crps=CRPS, skill=skill_score(CRPS))) %>%
  aggregate(cbind(crps, skill) ~ .model, FUN = "mean", drop = FALSE)

fc_daysSinceError %>% accuracy(rbind(tsrain, tsest), measures = list(crps=CRPS, skill=skill_score(CRPS))) %>%
  aggregate(cbind(crps, skill) ~ .model, FUN = "mean", drop = FALSE)

# Visualized:

```



```{r Fit winning forecast models with bootsraps}
# fit all (basic TSLM model) ([also fit something else to compare and pick TSLM?])
fit_volt <- model(tsrain, TSLM(volt ~ trend() + season()))
fit_rotate <- model(tsrain, TSLM(rotate ~ trend() + season()))
fit_pressure <- model(tsrain, TSLM(pressure ~ trend() + season()))
fit_vibration <- model(tsrain, TSLM(vibration ~ trend() + season()))
fit_daysSinceError <- model(tsrain, TSLM(daysSinceError ~ trend() + season()))

# forecast (with/without bootstrapping) (only TSLM)
fc_volt <- forecast(fit_volt, new_data = future_Q4[,1:2])
fc_volt_bs5 <- forecast(fit_volt, new_data = future_Q4[,1:2], bootstrap=T,times=5)
fc_volt_bs100 <- forecast(fit_volt, new_data = future_Q4[,1:2], bootstrap=T,times=100)

fc_rotate <- forecast(fit_rotate, new_data = future_Q4[,1:2])
fc_rotate_bs5 <- forecast(fit_rotate, new_data = future_Q4[,1:2], bootstrap=T,times=5)
fc_rotate_bs100 <- forecast(fit_rotate, new_data = future_Q4[,1:2], bootstrap=T,times=100)

fc_pressure <- forecast(fit_pressure, new_data = future_Q4[,1:2])
fc_pressure_bs5 <- forecast(fit_pressure, new_data = future_Q4[,1:2], bootstrap=T,times=5)
fc_pressure_bs100 <- forecast(fit_pressure, new_data = future_Q4[,1:2], bootstrap=T,times=100)

fc_vibration <- forecast(fit_vibration, new_data = future_Q4[,1:2])
fc_vibration_bs5 <- forecast(fit_vibration, new_data = future_Q4[,1:2], bootstrap=T,times=5)
fc_vibration_bs100 <- forecast(fit_vibration, new_data = future_Q4[,1:2], bootstrap=T,times=100)

fc_daysSinceError <- forecast(fit_daysSinceError, new_data = future_Q4[,1:2])
fc_daysSinceError_bs5 <- forecast(fit_daysSinceError, new_data = future_Q4[,1:2], bootstrap=T,times=5)
fc_daysSinceError_bs100 <- forecast(fit_daysSinceError, new_data = future_Q4[,1:2], bootstrap=T,times=100)
```






```{r Inspect residuals}
# FPP3 5.4

# autocorrelation ?


# Normality of residuals
gg_tsresiduals(fit_volt[fit_volt$machineID == 1,])
gg_tsresiduals(fit_rotate[fit_rotate$machineID == 1,])
gg_tsresiduals(fit_pressure[fit_pressure$machineID == 1,])
gg_tsresiduals(fit_vibration[fit_vibration$machineID == 1,])
gg_tsresiduals(fit_daysSinceError[fit_daysSinceError$machineID == 1,])

gg_tsresiduals(fit_volt[fit_volt$machineID == 1,])
gg_tsresiduals(fit_rotate[fit_rotate$machineID == 1,])
gg_tsresiduals(fit_pressure[fit_pressure$machineID == 1,])
gg_tsresiduals(fit_vibration[fit_vibration$machineID == 1,])
gg_tsresiduals(fit_daysSinceError[fit_daysSinceError$machineID == 1,])
# the residuals are not homoschedastic :(

# portmanteau tests - do the residuals come from white noise?
augment(fit_volt)%>%
  features(.innov, ljung_box, lag = 7)
# lb_pvalues are very small (on most machines), so it seems very, very unlikely that this is just white noise
```


```{r Forecast evaluation}
# scatterplot of forecast vs. real
plot(tsest$volt,fc_volt[fc_volt$.model=="tslm",]$.mean)

# FPP3 5.8 - Point forecast accuracy
# mean absolute error, mean squared error (in square scale), root mean squared error RMSE (back to normal scale), 
# mean absolute percentage error (scale-independant: takes away scale and becomes %)
accuracy(fit_volt) %>%
  select(machineID, MAE, MASE, RMSE, MAPE)
# are they going to have the same here because they are the same fit?

# FPP3 5.9 - distributional forecast accuracy
fc_volt %>%
  accuracy(rbind(tsrain, tsest), measures = list(qs=quantile_score), probs = 0.1) # estimating the 0.1 quantile
# interpretation: 

fc_volt %>%
  accuracy(rbind(tsrain, tsest), measures = list(winkler=winkler_score), levels = 80) # estimating the 80% confidence int
# winkler score = "width of the interval + penalty if you miss the actual observation"
# interpretation: lower ws is better

# Continuous ranked probability score (CRPS value)
fc_volt %>%
  accuracy(rbind(tsrain, tsest), measures = list(crps=CRPS))
# interpretation: lower is better. crps in in the unit of the data (e.g. volt)
# if we want something comparable and scale-independent, we use a skill scores
fc_volt %>%
  accuracy(rbind(tsrain, tsest), measures = list(skill=skill_score(CRPS)))
#Interpretation: High is good!
# if skill is negative, it is worse than the baseline (but what is the baseline?) "benchmark method (often naive)"
# It's percentage so -0.27 means 27% worse. 2.0 means twice as good
```


```{r fill in the rest of the predictors for the LogReg (Q4 + Q1)}
# make lag predictors (some rows based on real data, rest on forecasts)
```


```{r Failure prediction on forecasts (2015 Q4)}

```


```{r Evaluation of failure prediction Q4}

```


```{r Forecasts and failure prediction (2016 Q1)}
# cannot be evaluated as the data doesn't exist
# Just to illustrate how dashboard would look
```



```{r Trying to improve forecasts}
fit_volt <- model(tsrain, 
                  snaive=SNAIVE(volt),
                  tslm=TSLM(volt ~ trend() + season()), #Warning: 100 errors (1 unique) encountered for tslm
                  ets=ETS(volt ~ error() + trend() + season())) #[100] contrasts can be applied only to factors with 2 or more levels
fc_volt <- forecast(fit_volt, new_data = future_Q4)



machine_forecast(fc_volt, tsest, 4)




library(tsibbledata)
olympic_running %>%
  model(lm = TSLM(Time ~ trend()))
olympic_running %>%
  model(lm = TSLM(Time ~ trend())) %>%
  interpolate(olympic_running)

X <- tsrain %>%
  model(lm = TSLM(volt ~ trend() + season()))
Y <- tsrain %>%
  model(lm = TSLM(volt ~ trend() + season())) %>%
  interpolate(tsest)
# we can either (interpolate and merge) or (use forecast) but they don't give exactly the same value





#### following the book: ----
# predictors:
# model and age are unique for each machine, so that doesnt work?

# if it forecasts one row at a time, I may be able to use futureQ4 with the first few lag rows to forecast! :-D
# but that requires that it also puts a new value into the next lag row! :/

# otherwise, using predictors such as one variable to forecast another makes it post ante, not ex ante :(
# or we have to predict one of them first (which ever is best predicted ex ante) and use as predictor for the next, etc.

fit_volt_test <- model(tsrain,
                       simple_lm_lag1 = TSLM(volt ~ lag_1d_volt),
                       multi_lm_IoT = TSLM(volt ~ rotate + pressure + vibration)
                       #special_lm = TSLM(volt ~ trend())
                       ) 
fc_volt_test <- forecast(fit_volt_test, new_data = tsest)
machine_forecast(fc_volt_test, tsest, 1) 
# i can plot multiple machines with : operator,  but looks like it reduces complexity in real IoT measure

machine_report(fit_volt_test[,c(1,3)], 1)



# FPP3 5.5?
sim <- fit_volt |> generate(new_data = tsest, times = 5, bootstrap = TRUE)

tsrain[tsrain$date > "2015-09-01" & tsrain$machineID=="1",] |>
  ggplot(aes(x = date)) +
  geom_line(aes(y = volt)) +
  geom_line(aes(y = .sim, colour = as.factor(.rep)),
    data = sim[sim$machineID=="1" & sim$date < "2015-11-01",]) +
  #labs(title="Google daily closing stock price", y="$US" ) +
  guides(colour = "none")

tsrain[tsrain$machineID=="1",] |>
  ggplot(aes(x = date)) +
  geom_line(aes(y = volt)) +
  geom_line(aes(y = .sim, colour = as.factor(.rep)),
    data = sim[sim$machineID=="1",]) +
  #labs(title="Google daily closing stock price", y="$US" ) +
  guides(colour = "none")




# OLD forecast fitting code: ----
fit_volt <- model(tsrain, TSLM(volt ~ trend() + season()))
fc_volt <- forecast(fit_volt, new_data = future_Q4[,1:2])
machine_report(fit_volt, 1)
machine_forecast(fc_volt, tsest, 1)+ggtitle("TSLM(volt ~ trend() + season())                Machine1")


fit_volt <- model(tsrain, TSLM(volt ~ trend() + season()))
fc_volt <- forecast(fit_volt, new_data = future_Q4[,1:2], bootstrap =T, times=3)
machine_report(fit_volt, 1)
machine_forecast(fc_volt, tsest, 3)+ggtitle("TSLM(volt ~ trend() + season())  +bootstrap*3              Machine1")

fit_volt_STL <- model(tsrain, STL(volt))
components(fit_volt_STL)
```





